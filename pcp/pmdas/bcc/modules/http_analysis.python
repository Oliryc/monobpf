# Copyright (C) 2019 SnT
# Copyright (C) 2017-2018 Marko Myllynen <myllynen@redhat.com>
# Copyright (C) 2018 Andreas Gerstmayr <andreas@gerstmayr.me>
# Based on the tcplife module of BCC PMDA by Marko Myllynen and Andreas Gerstmayr:
# https://github.com/iovisor/bcc/blob/master/tools/tcplife.py
# Based on HTTP filter by Bertrone Matteo:
# https://github.com/iovisor/bcc/tree/master/examples/networking/http_filter
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
""" PCP BCC PMDA http_analysis module """

# pylint: disable=invalid-name, too-few-public-methods, too-many-instance-attributes

import ctypes as ct
from collections import deque, namedtuple
from functools import reduce
from threading import Lock, Thread
import time
import socket
import ipaddress
from socket import inet_ntop, AF_INET, AF_INET6
from struct import pack
from os import path, read
import re
import json

from bcc import BPF

from pcp.pmapi import pmUnits
from cpmapi import PM_TYPE_U32, PM_TYPE_U64, PM_TYPE_STRING, PM_SEM_INSTANT
from cpmapi import PM_SPACE_BYTE, PM_TIME_USEC
from cpmda import PMDA_FETCH_NOVALUES

from modules.pcpbcc import PCPBCCBase

# TODO:
# - IPv6 support?
# - Port filtering

#
# BPF program
#
bpf_src = "modules/http_analysis.bpf"
# Compat with kernel < 4.16, bcc < 0.6

#
# PCP BCC PMDA constants
#
MODULE = 'http_analysis'
BASENS = 'proc.io.net.http.'
units_bytes = pmUnits(1, 0, 0, PM_SPACE_BYTE, 0, 0)
units_usecs = pmUnits(0, 1, 0, 0, PM_TIME_USEC, 0)
units_none = pmUnits(0, 0, 0, 0, 0, 0)

# HTTP Metadata to be logged in PCP (some field may be empty). Note: headers are in a list because we need to be able to show duplicated key headers. Will be serialised as JSON array
HttpMetaRequest = namedtuple('HttpMetaRequest', 
                      [
                          'src_port',
                          'dst_port',
                          'src_ip',
                          'dst_ip',
                          'method', # GET, POST…
                          'path', # /path?key1=val1&key2=val2
                          'headers', # List containing dictionnary for key/value of HTTP headers
                          'is_websocket_upgrade', # Is detected as websocket upgrade?
                       ])
HttpMetaResponse = namedtuple('HttpMetaResponse', 
                      [
                          'src_port',
                          'dst_port',
                          'src_ip',
                          'dst_ip',
                          'code', # 404, 200…
                          'txt', # Not found…
                          'headers', # List containing dictionnary for key/value of HTTP headers
                          'is_websocket_upgrade', # Is detected as websocket upgrade?
                       ])
# For incorrect HTTP
HttpMetaIncorrect = namedtuple('HttpMetaIncorrect', 
                      [
                          'src_port',
                          'dst_port',
                          'src_ip',
                          'dst_ip',
                          'line', # Line analysed that resulted in being classified as incorrect
                       ])

CLEANUP_N_PACKETS  = 50       #run cleanup every CLEANUP_N_PACKETS packets received
MAX_URL_STRING_LEN = 8192     #max url string len (usually 8K)
MAX_AGE_SECONDS    = 30       #max age entry in bpf_sessions map
MAX_N_HEADER       = 30          #max number of header to be matched
CRLF               = "\r\n"      #HTTP separator
# Format of header from https://tools.ietf.org/html/rfc7230#section-3.2
HTTP_HEADER_REGEX       = re.compile(r'\A(.*?): ?(.*\S) ?\Z')  # To parse HTTP headers key/value


#
# PCP BCC Module
#
class PCPBCCModule(PCPBCCBase):
    """ PCP BCC tcplife module """
    def __init__(self, config, log, err, proc_refresh):
        """ Constructor """
        PCPBCCBase.__init__(self, MODULE, config, log, err)

        self.proc_refresh = proc_refresh

        # TODO Make some of these param of the config file
        self.debug = True
        self.interface = None
        self.dports = []
        self.sports = []
        self.ports = []
        self.ips = []
        self.session_count = 20
        self.bpf_sessions = None
        self.socket_fd = None
        self.buffer_page_count = 64
        self.bpf_text = None

        # To extract data from HTTP packets, we will use this regex
        http_request_or_answer = r'\A((?P<http_response>HTTP/1.1) (?P<code>\d+) (?P<txt>.*))|((?P<method>[A-Z]+) (?P<path>/\S*) (?P<http_request>HTTP/1.1))\Z'
        self.http_req_ans = re.compile(http_request_or_answer)

        for opt in self.config.options(MODULE):
            if opt == 'port':
                self.ports = [int(port) for port in self.config.get(MODULE, opt).split(",")]
                self.log("Filtering on local or remote ports: %s." % str(self.sports))
            if opt == 'dport':
                self.dports = [int(port) for port in self.config.get(MODULE, opt).split(",")]
                self.log("Filtering on remote ports: %s." % str(self.dports))
            if opt == 'sport':
                self.sports = [int(port) for port in self.config.get(MODULE, opt).split(",")]
                self.log("Filtering on local ports: %s." % str(self.sports))
            if opt == 'ip':
                packed = self.config.get(MODULE, opt).split(",")
                self.ips = [socket.inet_aton(ip) for ip in packed]
                self.log("Filtering on local ips: %s." % str(packed))
            if opt == 'interface': # Interface for the capture
                self.interface = self.config.get(MODULE, opt)
                self.log("Binding socket to: %s." % str(self.interface))

        if not self.interface:
            raise RuntimeError("interface is mandatory")

        self.cache = deque(maxlen=self.session_count)
        self.insts = {str(i) : ct.c_int(1) for i in range(self.session_count)}

        self.lock = Lock()
        self.thread = None

        self.log("Initialized.")

    #convert a bin string into a string of hex char
    #helper function to print raw packet in hex
    def toHex(self, s):
        lst = []
        for ch in s:
            if type(ch) is int:
                hv = hex(ch).replace('0x', '')
            else:
                hv = hex(ord(ch)).replace('0x', '')
            if len(hv) == 1:
                hv = '0'+hv
            lst.append(hv)

        return reduce(lambda x,y:x+y, lst)

    def substringUntilCRLF(self, string):
        """ Return substring from start to the first CRLF """
        l = string.split(CRLF, maxsplit=1)
        if len(l) > 1: # At least one substring
              return l[0]
        return ""

    #cleanup function
    def cleanup(self, ):
        #get current time in seconds
        current_time = int(time.time())
        #looking for leaf having:
        #timestap  == 0        --> update with current timestamp
        #AGE > MAX_AGE_SECONDS --> delete item
        for key,leaf in self.bpf_sessions.items():
          try:
            current_leaf = self.bpf_sessions[key]
            #set timestamp if timestamp == 0
            if (current_leaf.timestamp == 0):
              self.bpf_sessions[key] = self.bpf_sessions.Leaf(current_time)
            else:
              #delete older entries
              if (current_time - current_leaf.timestamp > MAX_AGE_SECONDS):
                del self.bpf_sessions[key]
          except:
            self.log("cleanup exception.")
        return

    def http_packet_poller(self):
        """ IP event handler """
        packet_count = 0

        #dictionary containing association <key(ipsrc,ipdst,portsrc,portdst),payload_string>
        #if url is not entirely contained in only one packet, save the firt part of it in this local dict
        #when I find \r\n in a next pkt, append and print all the url
        local_dictionary = {}

        while 1:
          #retrieve raw packet from socket
          packet_str = read(self.socket_fd,4096) # TODO set packet length to max packet length on the interface in the config file
          packet_count += 1

          #DEBUG - print raw packet in hex format
          #packet_hex = self.toHex(packet_str)
          #print ("%s" % packet_hex)

          #convert packet into bytearray
          packet_bytearray = bytearray(packet_str)

          #ethernet header length
          ETH_HLEN = 14

          #IP HEADER
          #https://tools.ietf.org/html/rfc791
          # 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
          # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
          # |Version|  IHL  |Type of Service|          Total Length         |
          # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
          #
          #IHL : Internet Header Length is the length of the internet header
          #value to multiply * 4 byte
          #e.g. IHL = 5 ; IP Header Length = 5 * 4 byte = 20 byte
          #
          #Total length: This 16-bit field defines the entire packet size,
          #including header and data, in bytes.

          #calculate packet total length
          total_length = packet_bytearray[ETH_HLEN + 2]               #load MSB
          total_length = total_length << 8                            #shift MSB
          total_length = total_length + packet_bytearray[ETH_HLEN+3]  #add LSB

          #calculate ip header length
          ip_header_length = packet_bytearray[ETH_HLEN]               #load Byte
          ip_header_length = ip_header_length & 0x0F                  #mask bits 0..3
          ip_header_length = ip_header_length << 2                    #shift to obtain length

          #retrieve ip source/dest
          ip_src_str = packet_str[ETH_HLEN+12:ETH_HLEN+16]                #ip source offset 12..15
          ip_dst_str = packet_str[ETH_HLEN+16:ETH_HLEN+20]                #ip dest   offset 16..19


          ip_src = int(self.toHex(ip_src_str),16)
          ip_dst = int(self.toHex(ip_dst_str),16)

          #TCP HEADER
          #https://www.rfc-editor.org/rfc/rfc793.txt
          #  12              13              14              15
          #  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
          # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
          # |  Data |           |U|A|P|R|S|F|                               |
          # | Offset| Reserved  |R|C|S|S|Y|I|            Window             |
          # |       |           |G|K|H|T|N|N|                               |
          # +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
          #
          #Data Offset: This indicates where the data begins.
          #The TCP header is an integral number of 32 bits long.
          #value to multiply * 4 byte
          #e.g. DataOffset = 5 ; TCP Header Length = 5 * 4 byte = 20 byte

          #calculate tcp header length
          tcp_header_length = packet_bytearray[ETH_HLEN + ip_header_length + 12]  #load Byte
          tcp_header_length = tcp_header_length & 0xF0                            #mask bit 4..7
          tcp_header_length = tcp_header_length >> 2                              #SHR 4 ; SHL 2 -> SHR 2

          #retrieve port source/dest
          port_src_str = packet_str[ETH_HLEN+ip_header_length:ETH_HLEN+ip_header_length+2]
          port_dst_str = packet_str[ETH_HLEN+ip_header_length+2:ETH_HLEN+ip_header_length+4]

          port_src = int(self.toHex(port_src_str),16)
          port_dst = int(self.toHex(port_dst_str),16)

          # Gather some of the TCP stream features
          tcp_ip_features = {'src_port': port_src, 'dst_port': port_dst,
                             'src_ip': str(ipaddress.ip_address(ip_src)),
                             'dst_ip': str(ipaddress.ip_address(ip_dst))}

          #calculate payload offset
          payload_offset = ETH_HLEN + ip_header_length + tcp_header_length

          #payload_string contains only packet payload
          payload_string = packet_str[(payload_offset):(len(packet_bytearray))].decode()

          #current_Key contains ip source/dest and port source/map
          #useful for direct bpf_sessions map access
          current_Key = self.bpf_sessions.Key(ip_src,ip_dst,port_src,port_dst)

          #looking for HTTP GET/POST request
          if ((payload_string[:3] == "GET") or (payload_string[:4] == "POST")   or (payload_string[:4] == "HTTP")  \
          or ( payload_string[:3] == "PUT") or (payload_string[:6] == "DELETE") or (payload_string[:4] == "HEAD") ):
            #match: HTTP GET/POST packet found
            if (CRLF in payload_string):
              #url entirely contained in first packet -> print it all
              (first_line, headers) = self.first_line_and_headers(payload_string)
              httpMeta = self.in_httpMeta(first_line, tcp_ip_features, headers)
              self.store_in_cache(httpMeta)

              # TODO Make detection of ws configurable
              # XXX Find a way to log this for PCP
              #  self.log("is_websocket_upgrade "+str(self.is_websocket_upgrade(httpMeta)))
              i, httpMeta2 = self.is_websocket_upgrade(httpMeta)
              if i:
                  self.log("======================== \/\/ ,/’ "+str(i))

              #delete current_Key from bpf_sessions, url already printed. current session not useful anymore
              try:
                del self.bpf_sessions[current_Key]
              except:
                self.error("error during delete from bpf map ")
            else:
              #url NOT entirely contained in first packet
              #not found \r\n in payload.
              #save current part of the payload_string in dictionary <key(ips,ipd,ports,portd),payload_string>
              local_dictionary[binascii.hexlify(current_Key)] = payload_string
          else:
            #NO match: HTTP GET/POST  NOT found

            #check if the packet belong to a session saved in bpf_sessions
            if (current_Key in self.bpf_sessions):
              #check id the packet belong to a session saved in local_dictionary
              #(local_dictionary mantains HTTP GET/POST url not printed yet because splitted in N packets)
              if (binascii.hexlify(current_Key) in local_dictionary):
                #first part of the HTTP GET/POST url is already present in local dictionary (prev_payload_string)
                prev_payload_string = local_dictionary[binascii.hexlify(current_Key)]
                #looking for CR+LF in current packet.
                if (CRLF in payload_string):
                  #last packet. containing last part of HTTP GET/POST url splitted in N packets.
                  #append current payload
                  prev_payload_string += payload_string
                  #print HTTP GET/POST url
                  substring = self.substringUntilCRLF(payload_string)
                  self.store_in_cache(substring, tcp_ip_features)
                  #clean bpf_sessions & local_dictionary
                  try:
                    del self.bpf_sessions[current_Key]
                    del local_dictionary[binascii.hexlify(current_Key)]
                  except:
                    print ("error deleting from map or dictionary")
                else:
                  #NOT last packet. containing part of HTTP GET/POST url splitted in N packets.
                  #append current payload
                  prev_payload_string += payload_string
                  #check if not size exceeding (usually HTTP GET/POST url < 8K )
                  if (len(prev_payload_string) > MAX_URL_STRING_LEN):
                    self.log("url too long")
                    try:
                      del self.bpf_sessions[current_Key]
                      del local_dictionary[binascii.hexlify(current_Key)]
                    except:
                      print ("error deleting from map or dict")
                  #update dictionary
                  local_dictionary[binascii.hexlify(current_Key)] = prev_payload_string
              else:
                #first part of the HTTP GET/POST url is NOT present in local dictionary
                #bpf_sessions contains invalid entry -> delete it
                try:
                    del self.bpf_sessions[current_Key]
                except Exception as e:
                    print ("error del bpf_session: "+str(e))

          #check if dirty entry are present in bpf_sessions
          if (((packet_count) % CLEANUP_N_PACKETS) == 0):
            self.cleanup()

    def first_line_and_headers(self, payload_string):
        """Extract first line (like 'GET /index.html HTTP/1.1') and headers that would be in the payload"""
        def split_header(http_header):
            kv = HTTP_HEADER_REGEX.match(http_header)
            if kv is None: return ""
            g1 = kv.group(1)
            g2 = kv.group(2)
            if g1 and g2: return {g1: g2}
        lines = payload_string.split(CRLF, MAX_N_HEADER)
        if len(lines) <= 1: # No CRLF in the payload
            return "", []
        headers = list(filter(
            lambda l: l != "",
            map(split_header, lines[1:])
        ))
        return lines[0], headers

    def in_httpMeta(self, http_line, tcp_ip_features, headers=[]):
        """ Extract data from an HTTP line like 'GET /index HTTP/1.1'
            or 'HTTP/1.1 404 Not Found' in an httpMeta* object
        """
        httpMeta = HttpMetaIncorrect(line=http_line, **tcp_ip_features)
        m = self.http_req_ans.match(http_line)
        if m is None:
            pass
        elif (m['http_response']):
            httpMeta = HttpMetaResponse(
                code=int(m['code']),
                txt=m['txt'],
                headers=headers,
                is_websocket_upgrade=False,
                **tcp_ip_features
            )
        elif (m['http_request']):
            httpMeta = HttpMetaRequest(
                method=m['method'],
                path=m['path'],
                headers=headers,
                is_websocket_upgrade=False,
                **tcp_ip_features
            )
        return httpMeta

    def store_in_cache(self, httpMeta):
        """ Store an httpMeta in cache, serialising fields when necessary """
        # Serialize headers
        t = type(httpMeta)
        if t is HttpMetaRequest or t is HttpMetaResponse:
            headers_str = json.dumps(httpMeta.headers)
            httpMeta = httpMeta._replace(headers = headers_str)

        self.lock.acquire()
        self.cache.appendleft(httpMeta)
        self.lock.release()

    def is_websocket_upgrade(self, httpMeta):
        """ Return non 0 code if the httpMeta* structure is a websocket upgrade. Return 1 for the client request and 2 for the server answer. See https://tools.ietf.org/html/rfc6455.
            The second return is the updated httpMeta
        """
        def put_header_dict_lower():
            """ Put all in one dictionary, with lower case key as they are case insensitive according to RFC. Account for the fact that key may be duplicated """
            headers_dict = {}
            for d in httpMeta.headers:
                for k,v in d.items(): # Should run once as these dictonary contain only one value
                    # Headers key are case insensitive
                    kl = k.lower()
                    l = headers_dict.get(kl, [])
                    l.append(v)
                    headers_dict[kl] = l
            return headers_dict

        def header_with_value(headers_dict, header_key, required_header_value):
            """ Return None if header_key is not in headers_dict.
                Return True if a given header_key is present with a value
                header_value (splitted on ',', case insensitive), False otherwise """
            key = header_key.lower()
            req_val = required_header_value.lower()

            if key not in headers_dict: return None
            for val in headers_dict[key]:
                if req_val in map(lambda l: l.lower(), val.split(", ")):
                    return True
            return False

        if type(httpMeta) is HttpMetaIncorrect:
            return 0, httpMeta
        # Page 21, https://tools.ietf.org/html/rfc6455#section-4.2.1, verifying only the minimum
        if type(httpMeta) is HttpMetaRequest:
            if httpMeta.method == "GET":
                headers_dict = put_header_dict_lower()
                if header_with_value(headers_dict, "upgrade", "websocket") \
                        and headers_dict.get("sec-websocket-key") \
                        and headers_dict.get("sec-websocket-version"):
                    hm2 = httpMeta._replace(is_websocket_upgrade=True)
                    return 1, hm2
            return 0, httpMeta
        # Page 19, https://tools.ietf.org/html/rfc6455#section-4.1, verifying only the minimum
        if type(httpMeta) is HttpMetaResponse:
            if httpMeta.code == 101:
                headers_dict = put_header_dict_lower()
                if header_with_value(headers_dict, "upgrade", "websocket") \
                        and header_with_value(headers_dict, "connection", "upgrade") \
                        and headers_dict.get("sec-websocket-accept"):
                    hm2 = httpMeta._replace(is_websocket_upgrade=True)
                    return 2, hm2
            return 0, httpMeta
        self.log("is_websocket_upgrade: incorrect type of argument")

    # pylint: disable=bad-continuation
    def metrics(self):
        """ Get metric definitions """
        name = BASENS
        self.items = (
            # Name - reserved - type - semantics - units - help
            (name + 'saddr', None, PM_TYPE_STRING, PM_SEM_INSTANT, units_none, 'source address'),
            (name + 'sport', None, PM_TYPE_U32, PM_SEM_INSTANT, units_none, 'source port'),
            (name + 'daddr', None, PM_TYPE_STRING, PM_SEM_INSTANT, units_none, 'destination '
                                                                               'address'),
            (name + 'dport', None, PM_TYPE_U32, PM_SEM_INSTANT, units_none, 'destination port'),
            (name + 'identifier', None, PM_TYPE_STRING, PM_SEM_INSTANT, units_none, 'method or code'),
            (name + 'param', None, PM_TYPE_STRING, PM_SEM_INSTANT, units_none, 'path or message'),
            (name + 'headers', None, PM_TYPE_STRING, PM_SEM_INSTANT, units_none, 'http headers'),
        )
        return True, self.items

    def compile(self):
        """ Compile BPF """
        try:
            if not self.bpf_text:
                with open(path.dirname(__file__) + '/../' + bpf_src) as src:
                    self.bpf_text = src.read()

                if self.ports:
                    filterp_dst = " && ".join(["key.dst_port != %d" % port for port in self.ports])
                    filterp_src = " && ".join(["key.src_port != %d" % port for port in self.ports])
                    filterp = " && ".join(["(%s)" % filt for filt in [filterp_dst, filterp_src]])
                    filter_txt = "if (%s) { goto DROP; }" % filterp
                    self.bpf_text = self.bpf_text.replace("//FILTER_LDPORT", filter_txt)
                if self.dports:
                    filterp = " && ".join(["key.dst_port != %d" % port for port in self.dports])
                    filter_txt = "if (%s) { goto DROP; }" % filterp
                    self.bpf_text = self.bpf_text.replace("//FILTER_DPORT", filter_txt)
                if self.sports:
                    filterp = " && ".join(["key.src_port != %d" % port for port in self.sports])
                    filter_txt = "if (%s) { goto DROP; }" % filterp
                    self.bpf_text = self.bpf_text.replace("//FILTER_LPORT", filter_txt)

                if self.ips:
                    filteri_dst = " && ".join(["key.dst_ip != 0x%s" % ip.hex() for ip in self.ips])
                    filteri_src = " && ".join(["key.src_ip != 0x%s" % ip.hex() for ip in self.ips])
                    filteri = " && ".join(["(%s)" % filt for filt in [filteri_dst, filteri_src]])
                    filter_txt = "if (%s) { goto DROP; }" % filteri
                    self.bpf_text = self.bpf_text.replace("//FILTER_IP", filter_txt)

            self.bpf = BPF(text=self.bpf_text)
            #load eBPF program http_filter of type SOCKET_FILTER into the kernel eBPF vm
            #more info about eBPF program types
            #http://man7.org/linux/man-pages/man2/bpf.2.html
            function_http_filter = self.bpf.load_func("http_filter", BPF.SOCKET_FILTER)
            #create raw socket, bind it to interface
            #attach bpf program to socket created
            BPF.attach_raw_socket(function_http_filter, self.interface)
            #get file descriptor of the socket previously created inside BPF.attach_raw_socket
            self.socket_fd = function_http_filter.sock
            #create python socket object, from the file descriptor
            sock = socket.fromfd(self.socket_fd, socket.PF_PACKET, socket.SOCK_RAW, socket.IPPROTO_IP)
            #set it as blocking socket
            sock.setblocking(True)
            self.bpf_sessions = self.bpf.get_table("sessions")

            if self.debug:
                self.log("BPF to be compiled:\n" + self.bpf_text.strip())

            self.thread = Thread(name="socketpoller", target=self.http_packet_poller)
            self.thread.setDaemon(True)
            self.thread.start()
            self.log("Compiled.")
        except Exception as error: # pylint: disable=broad-except
            self.bpf = None
            self.err(str(error))
            self.err("Module NOT active!")
            raise

    def refresh(self):
        """ Refresh BPF data """
        if self.bpf is None:
            return None

        return self.insts

    def bpfdata(self, item, inst):
        """ Return BPF data as PCP metric value """
        def noneOnAttrErr(attribute_access_function):
            """ Return None in case the attribute_access_function raises AttributeError """
            try:
                return attribute_access_function()
            except AttributeError:
                return None
        try:
            key = int(self.pmdaIndom.inst_name_lookup(inst))
            # h stands for httpMeta, as we match an HttpMetaIncorrect,
            # HttpMetaRequest or HttpMetaResponse object
            key_metrics_mapping = {
                0: lambda h: noneOnAttrErr(lambda: h.src_ip),
                1: lambda h: noneOnAttrErr(lambda: h.src_port),
                2: lambda h: noneOnAttrErr(lambda: h.dst_ip),
                3: lambda h: noneOnAttrErr(lambda: h.dst_port),
                # We are getting different type of object, we try in this order:
                # HttpMetaRequest or HttpMetaResponse or HttpMetaIncorrect
                4: lambda h: noneOnAttrErr(lambda: h.method) or noneOnAttrErr(lambda: str(h.code)) or None,
                5: lambda h: noneOnAttrErr(lambda: h.path) or noneOnAttrErr(lambda: h.txt) or noneOnAttrErr(lambda: h.line),
                6: lambda h: noneOnAttrErr(lambda: json.dumps(h.headers)) or noneOnAttrErr(lambda: json.dumps(h.headers)) or None,
            }

            self.lock.acquire()
            value = key_metrics_mapping[item](self.cache[key])
            self.lock.release()

            if value is not None:
                return [value, 1]
            else:
                return [PMDA_FETCH_NOVALUES, 0]
        except Exception as e: # pylint: disable=broad-except
            self.lock.release()
            self.log("bpfdata Exception: "+str(e))
            return [PMDA_FETCH_NOVALUES, 0]

